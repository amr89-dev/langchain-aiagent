{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqZM+4mXJo4tzJUZTYx595",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amr89-dev/langchain-aiagent/blob/main/Introduccion_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sW-dKDDajU3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe2a061-84ed-41e2-a0f3-26a8da196706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.6/587.6 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-google-genai langchain-openai chromadb pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from google.colab import userdata\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n"
      ],
      "metadata": {
        "id": "dtXyg-DJqcFh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",temperature=2)\n",
        "openai_llm = ChatOpenAI(model=\"gpt-5\")"
      ],
      "metadata": {
        "id": "sQfDhJGw2VhP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [(\"system\", \"Eres un profesor de ingles, entablas una conversación con un alumno, despues de cada respuesta del alumno le das feedback y correccion y sigues con la conversación\"),\n",
        "            (\"human\",\"Hola, que me enseñarás el dia de hoy\")]\n",
        "messages2 = [(\"system\",\"Eres un profesor de programación\"),\n",
        "             (\"human\", \"Enseñame a instalar python en windows\")]\n",
        "\n",
        "\n",
        "gemini_ai_msg = gemini_llm.invoke(messages2 )\n",
        "print(\"gemini -->\", gemini_ai_msg.content)\n",
        "#openai_ai_msg = openai_llm.invoke(messages)\n",
        "#print(\"OpenAi -->\",openai_ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSRD_Co585NR",
        "outputId": "74dcefbc-f1e6-4979-e2dc-657e682d2dc8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gemini --> ¡Excelente decisión! Has elegido el lenguaje de programación más popular y versátil del mundo. Como tu profesor, te guiaré paso a paso en la instalación de Python en tu sistema Windows. ¡Verás que es un proceso sencillo si sigues las instrucciones con atención!\n",
            "\n",
            "### Objetivo de la Clase: Instalar Python 3 en Windows y verificar su correcto funcionamiento.\n",
            "\n",
            "---\n",
            "\n",
            "### Paso 1: Descargar el Instalador de Python\n",
            "\n",
            "1.  **Dirígete a la Página Oficial:** Abre tu navegador web y visita la página oficial de Python: [https://www.python.org/downloads/windows/](https://www.python.org/downloads/windows/)\n",
            "\n",
            "2.  **Elige la Versión Correcta:**\n",
            "    *   Encontrarás varias versiones disponibles. Te recomiendo **descargar siempre la última versión estable de Python 3.x.x** (por ejemplo, Python 3.12.x o la más reciente que veas).\n",
            "    *   Fíjate en las opciones \"Windows installer (64-bit)\" y \"Windows installer (32-bit)\". La mayoría de los ordenadores modernos usan 64 bits. Si tu Windows es muy antiguo o no estás seguro, puedes verificarlo haciendo clic derecho en \"Este equipo\" o \"Mi PC\" > \"Propiedades\". **Elige la versión de 64-bit si tu sistema lo es.**\n",
            "\n",
            "    *   **Acción:** Haz clic en el enlace para descargar el instalador `Windows installer (64-bit)`. El archivo se descargará en tu carpeta de \"Descargas\" y tendrá un nombre similar a `python-3.x.x-amd64.exe`.\n",
            "\n",
            "### Paso 2: Ejecutar el Instalador de Python\n",
            "\n",
            "Una vez que el archivo `.exe` se haya descargado:\n",
            "\n",
            "1.  **Localiza y Ejecuta:** Navega a tu carpeta de descargas y haz doble clic en el archivo `.exe` que acabas de descargar (por ejemplo, `python-3.x.x-amd64.exe`).\n",
            "\n",
            "2.  **Configuración del Instalador (¡Mucha Atención Aquí!):**\n",
            "    *   Aparecerá una ventana llamada \"Install Python 3.x.x (64-bit)\".\n",
            "    *   **¡Este es el paso más IMPORTANTE para evitar problemas futuros!**\n",
            "        *   En la parte inferior de esta ventana, asegúrate de **marcar la casilla que dice `Add python.exe to PATH`**.\n",
            "        *   **¿Por qué es importante?** Marcar esta casilla hará que Python esté disponible directamente desde tu Símbolo del Sistema (CMD) o PowerShell, lo cual es fundamental para ejecutar scripts y usar herramientas como `pip` (el gestor de paquetes de Python). Si olvidas marcarla, tendrás que añadirlo manualmente, lo cual es más complicado para un principiante.\n",
            "    *   Ahora, tienes dos opciones:\n",
            "        *   **\"Install Now\" (Recomendado para la mayoría de usuarios):** Esta opción realizará una instalación estándar con las configuraciones por defecto.\n",
            "        *   \"Customize installation\": Permite elegir componentes y la ruta de instalación, útil para usuarios avanzados o si necesitas múltiples versiones de Python. **Para esta primera instalación, elige \"Install Now\".**\n",
            "\n",
            "3.  **Proceso de Instalación:**\n",
            "    *   Windows puede pedirte permiso de administrador. Haz clic en \"Sí\".\n",
            "    *   La instalación comenzará y puede tardar unos minutos. Verás una barra de progreso.\n",
            "\n",
            "4.  **Finalización:**\n",
            "    *   Una vez completada la instalación, verás un mensaje que dice \"Setup was successful\" o \"Installation complete\".\n",
            "    *   Si aparece la opción \"Disable path length limit\", puedes hacer clic en ella si lo deseas (es una opción avanzada para manejar rutas de archivo muy largas, generalmente no es necesaria para un uso básico, pero no hace daño activarla).\n",
            "    *   Haz clic en \"Close\".\n",
            "\n",
            "---\n",
            "\n",
            "### Paso 3: Verificar la Instalación\n",
            "\n",
            "¡Muy bien! Ahora necesitamos confirmar que Python se ha instalado correctamente y que está accesible desde tu terminal.\n",
            "\n",
            "1.  **Abrir el Símbolo del Sistema (CMD) o PowerShell:**\n",
            "    *   Puedes presionar la tecla `Windows + R`, escribir `cmd` y presionar Enter.\n",
            "    *   O bien, buscar \"Símbolo del sistema\" o \"PowerShell\" en la barra de búsqueda de Windows y abrirlo.\n",
            "\n",
            "2.  **Verificar la Versión de Python:**\n",
            "    *   En la ventana del Símbolo del sistema, escribe el siguiente comando y presiona Enter:\n",
            "        ```bash\n",
            "        python --version\n",
            "        ```\n",
            "    *   **Resultado esperado:** Deberías ver la versión de Python que acabas de instalar (por ejemplo, `Python 3.12.0`).\n",
            "\n",
            "3.  **Verificar la Versión de Pip:**\n",
            "    *   `pip` es el gestor de paquetes de Python, vital para instalar librerías. Si Python se instaló correctamente con PATH, `pip` también debería funcionar. Escribe:\n",
            "        ```bash\n",
            "        pip --version\n",
            "        ```\n",
            "    *   **Resultado esperado:** Deberías ver la versión de pip (por ejemplo, `pip 23.2.1 from ...`).\n",
            "\n",
            "    *   **¡Felicidades!** Si ambos comandos devuelven la versión correspondiente sin errores, ¡has instalado Python exitosamente en tu sistema Windows!\n",
            "\n",
            "---\n",
            "\n",
            "### Paso 4 (Opcional pero muy Recomendado): Configurar un Entorno de Desarrollo\n",
            "\n",
            "Aunque puedes escribir código Python en cualquier editor de texto (como el Bloc de Notas), usar un buen entorno de desarrollo integrado (IDE) o editor de código hará tu vida mucho más fácil. Mi recomendación para empezar es **Visual Studio Code (VS Code)**.\n",
            "\n",
            "1.  **Descargar VS Code:** Ve a [https://code.visualstudio.com/download](https://code.visualstudio.com/download) y descarga el instalador de Windows.\n",
            "2.  **Instalar VS Code:** Ejecuta el instalador, aceptando los términos y, si lo deseas, marcando las opciones para \"Add 'Open with Code' action to Windows Explorer file context menu\" (útil).\n",
            "3.  **Instalar la Extensión de Python en VS Code:**\n",
            "    *   Abre VS Code.\n",
            "    *   Haz clic en el icono de \"Extensiones\" en la barra lateral izquierda (parece un cuadrado superpuesto).\n",
            "    *   En la barra de búsqueda de extensiones, escribe `Python`.\n",
            "    *   Busca la extensión \"Python\" de **Microsoft** (suele ser la primera o una de las primeras).\n",
            "    *   Haz clic en el botón \"Install\".\n",
            "\n",
            "---\n",
            "\n",
            "### ¡Ahora, a Programar tu Primer \"Hola Mundo\"!\n",
            "\n",
            "Vamos a asegurarnos de que todo funcione creando un pequeño script.\n",
            "\n",
            "1.  **Crear una Carpeta de Proyectos:**\n",
            "    *   Crea una nueva carpeta en un lugar fácil de recordar, por ejemplo, `C:\\proyectos_python` o `C:\\Users\\TuUsuario\\Documentos\\PythonProjects`.\n",
            "\n",
            "2.  **Crear el Archivo Python:**\n",
            "    *   Abre VS Code.\n",
            "    *   Ve a `File` > `Open Folder...` y selecciona la carpeta que acabas de crear.\n",
            "    *   Una vez abierta la carpeta, haz clic en el icono \"New File\" (el papelito con el signo +) en la barra lateral izquierda (Explorer).\n",
            "    *   Nombra el archivo `hola_mundo.py` (¡la extensión `.py` es crucial!).\n",
            "    *   Dentro de `hola_mundo.py`, escribe la siguiente línea de código:\n",
            "        ```python\n",
            "        print(\"¡Hola Mundo desde Python y Windows!\")\n",
            "        ```\n",
            "    *   Guarda el archivo (`Ctrl + S` o `File > Save`).\n",
            "\n",
            "3.  **Ejecutar tu Primer Script:**\n",
            "    *   Abre tu Símbolo del Sistema (CMD) o PowerShell.\n",
            "    *   Navega a la carpeta donde guardaste tu archivo usando el comando `cd` (change directory). Por ejemplo:\n",
            "        ```bash\n",
            "        cd C:\\Users\\TuUsuario\\Documentos\\PythonProjects\n",
            "        ```\n",
            "        (Asegúrate de cambiar la ruta a la de tu carpeta).\n",
            "    *   Una vez dentro de la carpeta, ejecuta tu script con el siguiente comando:\n",
            "        ```bash\n",
            "        python hola_mundo.py\n",
            "        ```\n",
            "    *   **Resultado esperado:** Verás en tu terminal:\n",
            "        ```\n",
            "        ¡Hola Mundo desde Python y Windows!\n",
            "        ```\n",
            "\n",
            "---\n",
            "\n",
            "### Solución de Problemas Comunes (FAQ)\n",
            "\n",
            "*   **\"Python no se reconoce como un comando interno o externo\"**:\n",
            "    *   **Causa:** Casi siempre significa que no marcaste la casilla `Add python.exe to PATH` durante la instalación.\n",
            "    *   **Solución:** La forma más fácil es desinstalar Python desde el \"Panel de Control\" (o \"Configuración\" > \"Aplicaciones\") y volver a instalarlo, ¡asegurándote de marcar la casilla! Si no quieres reinstalar, puedes añadirlo manualmente al PATH de Windows, pero es un poco más avanzado.\n",
            "\n",
            "*   **\"Error al ejecutar pip\"**:\n",
            "    *   **Causa:** Mismo problema que el PATH, ya que pip se instala junto con Python.\n",
            "    *   **Solución:** Reinstala Python asegurándote de marcar la casilla `Add python.exe to PATH`.\n",
            "\n",
            "*   **¿Qué hago si tengo múltiples versiones de Python?**:\n",
            "    *   Windows puede manejar esto, pero para empezar, te recomiendo tener una sola versión instalada. Si el instalador te ofrece la opción de \"Modify\", \"Repair\" o \"Uninstall\" y detecta una versión previa, lo mejor es desinstalar las versiones antiguas si no las necesitas específicamente, para evitar conflictos al iniciar. El lanzador `py` (ej: `py -3.9` para Python 3.9) también ayuda, pero es un tema más avanzado.\n",
            "\n",
            "---\n",
            "\n",
            "¡Excelente trabajo! Has dado un paso gigante en tu viaje de programación. La instalación y configuración inicial son a menudo los obstáculos más tediosos, ¡pero los has superado con éxito! Ahora tienes tu entorno listo para empezar a aprender y crear con Python. Si tienes alguna duda, no dudes en preguntar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PromptTemplate\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = PromptTemplate.from_template(\"Dime un chiste de {topic}\")\n",
        "\n",
        "chain = prompt_template | openai_llm\n",
        "\n",
        "print(chain.invoke({\"topic\": \"ciencia\"}).content)\n",
        "prueba = chain.invoke({\"topic\": \"ciencia\"})\n",
        "print(\"respuesta --->\",prueba.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBbNP6fmeyzN",
        "outputId": "7028ffae-0663-4697-fc01-d2c06fabc555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un fotón entra a un hotel. El recepcionista le pregunta: ¿Necesita ayuda con su equipaje? El fotón responde: No, viajo sin carga.\n",
            "respuesta ---> Le conté un chiste de química a mis amigos… no hubo reacción.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([(\"system\", \"Eres un traductor de {input_language}, y. traduces el texto a {output_language}\"),\n",
        "                                      (\"human\",\"Hola, puedes traducir: {input_human}\")])\n",
        "\n",
        "chain = prompt | gemini_llm\n",
        "\n",
        "print(chain.invoke({\"input_language\": \"Español\", \"output_language\": \"Aleman\", \"input_human\": \"Quiero mas comida\"}).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y0hC6-UpbhL",
        "outputId": "12b81bd6-8d61-44ad-c5bb-d2d58d9047aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro, aquí tienes:\n",
            "\n",
            "**Ich möchte mehr Essen**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Eres un profesor de ingles, entablas una conversación con un alumno, despues de cada respuesta del alumno le das feedback y correccion y sigues con la conversación\"),\n",
        "    MessagesPlaceholder(\"user_msg\"),\n",
        "\n",
        "])\n",
        "\n",
        "print(prompt_template.invoke({\"user_msg\": [HumanMessage(content=\"Hola\"), HumanMessage(content=\"Que me enseñarás el dia de hoy?\")]}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn_QGJTxftR1",
        "outputId": "faa37e5a-f17a-4332-86e5-92892a1e128d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "messages=[SystemMessage(content='Eres un profesor de ingles, entablas una conversación con un alumno, despues de cada respuesta del alumno le das feedback y correccion y sigues con la conversación', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hola', additional_kwargs={}, response_metadata={}), HumanMessage(content='Que me enseñarás el dia de hoy?', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PromptTemplate - Few Shot\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "\n",
        "few_shots_examples = [{\"input\": \"2 s 2\", \"output\": \"4\"}, {\"input\": \"2 s 3\", \"output\": \"5\"}]\n",
        "\n",
        "prompt_template = ChatPromptTemplate([(\"human\", \"{input}\"),(\"ai\", \"{output}\")])\n",
        "\n",
        "few_shot_prompt_template = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=prompt_template,\n",
        "    examples=few_shots_examples,\n",
        "\n",
        ")\n",
        "\n",
        "# print(few_shot_prompt_template.invoke({}).to_messages()) Es la plantilla completa para pasar al ChatPromptTemplate\n",
        "\n",
        "main_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Eres un experto en matematicas\"),\n",
        "    few_shot_prompt_template,\n",
        "    (\"human\", \"{input}\"),\n",
        "\n",
        "])\n",
        "\n",
        "#Cadenas\n",
        "\n",
        "chain = main_prompt_template | gemini_llm\n",
        "\n",
        "print(chain.invoke({\"input\": \"3 s 22\"}).content)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NMHpx6mmESY",
        "outputId": "74adcc0a-50f1-445f-8340-44969658624d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output Parser\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([(\"system\", \"Traduce lo siguient al idioma {language}\"), (\"human\", \"{text}\")])\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "chain = prompt_template | gemini_llm| parser\n",
        "print(chain.invoke({\"language\": \"Español\", \"text\": \"Hello world\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXnx0kXl-E-U",
        "outputId": "1169a032-2b89-4f32-eb2e-57c0155b6786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Hola mundo\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat con historial\n",
        "\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "if not chat_history:\n",
        "  system_message = SystemMessage(content=\"Eres un profesor de ingles, entablas una conversación con un alumno, despues de cada respuesta del alumno le das feedback y correccion y sigues con la conversación en ingles\"\n",
        "    )\n",
        "  chat_history.append(system_message)\n",
        "\n",
        "query = input(\"Human: \")\n",
        "\n",
        "human_message = HumanMessage(content=query)\n",
        "chat_history.append(human_message)\n",
        "\n",
        "ai_message = gemini_llm.invoke(chat_history)\n",
        "chat_history.append(AIMessage(content=ai_message))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WCI4EyQO0unG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf7e3e7-43cb-4464-bdbc-9efc758a67e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human: I think that learn langchian is very interesting and challenging because is a new world for me\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for message in chat_history:\n",
        "  print(message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc4KkOOeJZiz",
        "outputId": "6e3c1798-4781-440f-ab45-8eb8c69e01d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eres un profesor de ingles, entablas una conversación con un alumno, despues de cada respuesta del alumno le das feedback y correccion y sigues con la conversación en ingles\n",
            "I think that learn langchian is very interesting and challenging because is a new world for me\n",
            "That's a great start! I completely understand what you're trying to say, and you've hit on some key points about language learning. Let's make a few small adjustments to make your sentence perfect.\n",
            "\n",
            "Here's the feedback:\n",
            "\n",
            "1.  **Typo Correction:** You wrote \"langchian.\" I assume you meant **\"language.\"** It's a very common typo!\n",
            "2.  **Gerund/Infinitive:** When you use a verb as the subject of a sentence (what the sentence is about), it usually takes the \"-ing\" form (a gerund). So, \"learn langchian\" should be **\"learning a language.\"** Alternatively, you could say \"to learn a language.\"\n",
            "3.  **Missing Subject Pronoun:** You wrote \"because is a new world.\" After \"because,\" you need a subject. So, it should be **\"because it is a new world\"** or the more common contracted form **\"because it's a new world.\"**\n",
            "\n",
            "So, your sentence, with these corrections, would be:\n",
            "\n",
            "\"I think that **learning a language** is very interesting and challenging because **it is** a new world for me.\" (Or \"because **it's** a new world for me.\")\n",
            "\n",
            "See? Much clearer! But your original idea was excellent.\n",
            "\n",
            "You said it's \"a new world.\" That's a fascinating way to describe it! Can you tell me more about what you mean by that? What aspects of this \"new world\" do you find most interesting or most challenging? For example, is it the grammar, the vocabulary, the pronunciation, or maybe even the cultural insights you gain?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Runnables encadenan funciones y pasan la salida a la siguiente función\n",
        "\n",
        "%pip install -qU langchain langchain-core\n",
        "\n",
        "\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "sequence1 = RunnableLambda(lambda x: x + 1) | RunnableLambda(lambda x: x * x)\n",
        "\n",
        "result1 = sequence1.invoke(2)\n",
        "\n",
        "print(result1)\n",
        "\n",
        "\n",
        "sequence2 = RunnableLambda(lambda x: x + 1) | {\n",
        "    \"square\": RunnableLambda(lambda x: x * x),\n",
        "    \"cube\": RunnableLambda(lambda x: x * x * x)\n",
        "}\n",
        "result2 = sequence2.invoke(2)\n",
        "\n",
        "print(result2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKekl870KYVi",
        "outputId": "b3f1f536-0742-46dd-93a7-4b8060f2c9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "{'square': 9, 'cube': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OutputParser\n",
        "\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "query = input()\n",
        "parser = JsonOutputParser()\n",
        "\n",
        "prompt_template = PromptTemplate(template= \"Responde la pregunta del usuario. \\n {format_instructions} \\n {query}\",\n",
        "                                 input_variables=[\"query\"],\n",
        "                                 partial_variables={\"format_instructions\": parser.get_format_instructions()}) # partial_variables es para indicar el formato de salida\n",
        "\n",
        "chain = prompt_template | gemini_llm | parser\n",
        "\n",
        "res = chain.invoke({\"query\": query})\n",
        "\n",
        "\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7HtIRqAbZus",
        "outputId": "7265186f-eda6-4786-abb1-23f7b1260454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "como viaja la luz\n",
            "{'respuesta': 'La luz viaja de varias maneras y se puede describir desde diferentes perspectivas, pero fundamentalmente lo hace como **ondas electromagnéticas**. Esto implica varios puntos clave:\\n\\n1.  **Ondas Electromagnéticas:** La luz no es una onda mecánica (como el sonido) que necesite un medio físico para propagarse. En cambio, son oscilaciones de campos eléctricos y magnéticos que se generan y propagan perpendicularmente entre sí y a la dirección de viaje.\\n2.  **Viaja en el Vacío:** Debido a que no necesita un medio, la luz puede viajar y lo hace a través del vacío (el espacio exterior) sin problemas, a diferencia del sonido. \\n3.  **Velocidad de la Luz:** Viaja a una velocidad constante y finita en el vacío, que es la velocidad máxima conocida en el universo: aproximadamente 299,792,458 metros por segundo (o unos 300,000 kilómetros por segundo).\\n4.  **Dualidad Onda-Partícula:** En un nivel más fundamental, la luz también se comporta como una partícula llamada **fotón**. Así, exhibe una dualidad onda-partícula, actuando como una onda en su propagación y como un paquete discreto de energía (fotón) en sus interacciones con la materia.\\n5.  **Propagación Rectilínea:** En medios uniformes y sin obstáculos, la luz viaja en línea recta (propagación rectilínea), como demuestran fenómenos como las sombras.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "query = input()\n",
        "\n",
        "#Stream\n",
        "\n",
        "#for s in chain.stream({\"query\": query}):\n",
        "  # print(s)\n",
        "  #time.sleep(0.3)\n",
        "\n",
        "chunks = []\n",
        "\n",
        "async for chunk in openai_llm.astream(query):\n",
        "  chunks.append(chunk)\n",
        "  print( chunk.content, end=\"-\", flush=True)\n",
        "  time.sleep(0.05)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0TGB-uSSg1zq",
        "outputId": "c7958b2b-441b-40b3-9dd7-1e8e371f5a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dime un poema\n",
            "-Hay- un- rumor- de- luces- en- la- calle-,\n",
            "-un- pul-so- tib-io- en- la- cost-ura- del- as-falto-.\n",
            "-La- noche-,- cost-ur-era- de- silenc-ios-,\n",
            "-hil-vana- cic-atrices- con- hilo- de- far-oles-.\n",
            "\n",
            "-Sobre- los- balcon-es-,- la- ropa- sue-ña-\n",
            "-ser- viento- alguna- vez-.\n",
            "-Un- gato- bebe- estrellas- en- las- te-jas-\n",
            "-y- el- agua- memor-iza- el- nombre- de- la- lluvia-.\n",
            "\n",
            "-Tu- nombre- cru-za- la- ciudad- como- un- tran-v-ía-,\n",
            "-l-ento-,- lleno- de- ventanas-.\n",
            "-Yo- le- hago- señ-as- desde- una- esquina- de- humo-,\n",
            "-pero- pasa- y- me- deja- la- moneda- de- su- eco-.\n",
            "\n",
            "-Cuando- am-ane-ce-,- el- mundo- h-uele- a- pan-,\n",
            "-y- el- tiempo-,- como- un- niño-,- se- des-cal-za-.\n",
            "-Entonces- entiendo-:\n",
            "-todo- lo- que- am-amos- vuelve-\n",
            "-en- forma- de- luz- que- tarda-.--[AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='Hay', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' un', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' rumor', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' de', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' luces', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' en', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' la', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' calle', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=',\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='un', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' pul', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='so', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' tib', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='io', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' en', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' la', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' cost', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='ura', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' del', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='falto', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='La', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' noche', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' cost', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='ur', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='era', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' de', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' silenc', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='ios', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=',\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='hil', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='vana', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' cic', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='atrices', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' con', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' hilo', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' de', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' far', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='oles', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='Sobre', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' los', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' balcon', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='es', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' la', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' ropa', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' sue', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='ña', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='ser', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' viento', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' alguna', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' vez', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='Un', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' gato', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' bebe', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' estrellas', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' en', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' las', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' te', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='jas', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='y', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' el', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' agua', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' memor', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='iza', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' el', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' nombre', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' de', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' la', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' lluvia', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='Tu', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' nombre', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' cru', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='za', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' la', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' ciudad', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' como', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' un', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' tran', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='v', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='ía', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=',\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='l', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='ento', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' lleno', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' de', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' ventanas', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='Yo', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' le', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' hago', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' señ', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='as', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' desde', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' una', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' esquina', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' de', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' humo', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=',\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='pero', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' pasa', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' y', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' me', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' deja', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' la', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' moneda', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' de', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' su', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' eco', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='Cuando', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' am', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='ane', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='ce', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' el', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' mundo', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' h', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='uele', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' pan', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=',\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='y', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' el', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' tiempo', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' como', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' un', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' niño', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' se', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' des', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='cal', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='za', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='Entonces', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' entiendo', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=':\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='todo', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' lo', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' que', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' am', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='amos', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' vuelve', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='en', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' forma', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' de', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' luz', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' que', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content=' tarda', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72'), AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-5-2025-08-07', 'service_tier': 'default'}, id='run--4314cf8f-9f62-4f1f-977a-f6d6b4833c72')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat Memory\n",
        "\n",
        "from langchain_core.chat_history import (\n",
        "    BaseChatMessageHistory,\n",
        "    InMemoryChatMessageHistory,\n",
        ")\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = { }\n",
        "\n",
        "# Esta funcion nos permite guardar historial de chat basado en el session id\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(openai_llm, get_session_history)\n",
        "config = { \"configurable\": {\"session_id\": \"user_1\"}}\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"Hola, que me enseñes el dia de hoy\")],\n",
        "    config=config\n",
        ")\n"
      ],
      "metadata": {
        "id": "hVmeRsy4l5vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lLND3ccXJZIn"
      }
    }
  ]
}